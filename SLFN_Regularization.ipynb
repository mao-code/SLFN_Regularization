{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mao-code/SLFN_Regularization/blob/main/SLFN_Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH-VZtf4LqsW"
      },
      "source": [
        "# This is based on the HW4 of New Learning Algorithm class (To handle overfitting)\n",
        "Using regularizing module. Not just using weight_tuning_r\n",
        "\n",
        "<img\n",
        "width=\"500px\"\n",
        "src=\"https://lh3.googleusercontent.com/fife/APg5EOZ3hBraPY_Aa_TvGC-NZDWh5IpjnJf6kCwI3NKKrgO3kswHjrAtc32_iiwHx_OiEylmWEvnKGSpU_XK-kLtIHu2u0JBpLiBIlEe0wueEsaqs2_Xtxsl_udgl6jW61Z2965WnmZZYFla7zyEgu6JSmd9P9H62NhRHpZgdpX95J7kmPmPcTyUxJa_Ua6FXJ9J2b_yrgpPN3x_6eA8wm8x2S8xS0A_dmbZbkbC0j_X1VKhvirgLfQygawq0uaaIf5FRE16xrBuSwQ7pZoj2Eyk_GO1YKbFaXjb3lsj8j05TjPHdTYC0S-xflbgKANERDNe6tG3MttAnhgPi32wAqgdbLYNqea3cV6vLgEyK9feGTQpioYgPTREj_idBef-Tz9ztFPUsHInV4yk1A92wgfFI73_3dCEwkifWp5Amdx2zyN0kNkmrdntOy6cMt7-hcf0UydEJ8rNSL5Vd8kzNIicCg-UjXYvplti6VNMk1n5HY7SVupD2FL_c8UUKZVApkDzTeh71lDGL8i5A1H-QMQGcXfrZjzpCamrHiMDJRFZi5NIvJ3A4fx25PjbMVhePhgzrazM62vlXRWcHww-U4wCMBn1wh2WTQ6Aa3mN8LOAdiw8j7abWfTpEoABI18KoanH7xs2AWPTFdxPCXHmwg3XieaTlBPU943WiRmMRblI2cMDxVsiBojUQ-jwXAlsEQDfYt_bHvFlHQfu5j_byjHXjhEZjPcAu0pAdDIMrYDogp9o2toDjJHy2f9ziuMOYayncA_DP5EgTJLjgG5AVaOABRDGmV07ar5FxEEhXpk9E07KNSTiERq2g3g2SIwnalP8wP9d7yRfzNNRwsqYjsNGs65g-4iEoGKjpZnlyTgXoHrKFv6MooeOkiucbe8MsIneNQ-vQraaxmJwvFTbsewz_XzIDZlxLWVyCdpzowvoJtlDhZL3XU6MgsuCsGIx1wDVC_Fg_1EpxHxXsvZDch1tnYHPq1QkEuKxn3goHSOUW4plGytXJp8PucPz0IyD8Pke47h0_9ryNgqChFa1ml7xZWTu57A_7UFaarwUUIAPAZaxpzdNw0y8Rz21YJWk32iTOi5t-kYT80XMQXzOvii4pTlov7QW2VQMJ0W_YCbh9bDCnJ7TyMt_SsKKb_KrLBZ6ZaCgFuuKao_0igHQeT6r_tsb5urljjikb2GyDvchuZbl4aPC-B5UnLK9HAyPzdw7hdHiKYyiO2wxKNbk9fDDwI8Gzgvd2TdxXhPIbX-s9SkKIb9B833448J1JXRPDlQvSXpXTfNSNQQlixV-XG1dhIrMSDCKu3iehUPOUXzGguMCTIKz_jVNZDfM5AnbgEaXBqLJDjVrNxNcvQdiH7WWxHKNR-IETCwXVlUMzUXlr4D8QRg9_xHvPF-HvxptVjPIuRmNpdXRnATisl9rjYlgC6j78qNlLrkYBHZVcCadZ87sDI-SyaE1HAE-m_tnLfm0uPFQ_2N9Bb8hG-0qVmmNQmSbfvcI5twSSXSsuTVhJ7thdPwiTLIk23ynGVzFyJJC1ZiiOl3L6T6zYB7EDBS5NoxjXNGqHY05A_xoOlHssvxllKvGP79U1IK2rhsff1WMUcY=w1912-h1566\"\n",
        "alt=\"HW4\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Ce9rIzOFIRy-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rlm4ms-NVJC"
      },
      "source": [
        "## Setup seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2ILlJF3YMatY"
      },
      "outputs": [],
      "source": [
        "def setup_seed(seed):\n",
        "   torch.manual_seed(seed)\n",
        "   torch.cuda.manual_seed(seed)\n",
        "   torch.cuda.manual_seed_all(seed)\n",
        "   np.random.seed(seed)\n",
        "   random.seed(seed)\n",
        "   torch.backends.cudnn.benchmark = False\n",
        "   torch.backends.cudnn.deterministic = True\n",
        "   torch.backends.cudnn.enabled = True\n",
        "\n",
        "setup_seed(8888)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnKL2NwxNXSo"
      },
      "source": [
        "## Data constructing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "jTbBHluyNOAO"
      },
      "outputs": [],
      "source": [
        "housing_train_df = pd.read_csv('sample_data/california_housing_train.csv')\n",
        "housing_test_df = pd.read_csv('sample_data/california_housing_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "Um09O5XoNe0z",
        "outputId": "b2a47cff-2a40-4206-bd4a-4519e323fa0c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-35a4a362-ec7d-4342-8375-a3541367ed76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.623352</td>\n",
              "      <td>-0.672591</td>\n",
              "      <td>-1.083095</td>\n",
              "      <td>1.366966</td>\n",
              "      <td>1.771168</td>\n",
              "      <td>-0.362989</td>\n",
              "      <td>-0.072107</td>\n",
              "      <td>-1.251624</td>\n",
              "      <td>-1.213104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.543496</td>\n",
              "      <td>-0.574283</td>\n",
              "      <td>-0.765186</td>\n",
              "      <td>2.303412</td>\n",
              "      <td>3.240388</td>\n",
              "      <td>-0.262197</td>\n",
              "      <td>-0.095684</td>\n",
              "      <td>-1.079867</td>\n",
              "      <td>-1.098875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.498578</td>\n",
              "      <td>-0.906658</td>\n",
              "      <td>-0.924141</td>\n",
              "      <td>-0.880871</td>\n",
              "      <td>-0.865347</td>\n",
              "      <td>-0.965969</td>\n",
              "      <td>-1.002085</td>\n",
              "      <td>-1.168851</td>\n",
              "      <td>-1.050414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.493587</td>\n",
              "      <td>-0.930065</td>\n",
              "      <td>-1.162572</td>\n",
              "      <td>-0.522007</td>\n",
              "      <td>-0.477834</td>\n",
              "      <td>-0.805056</td>\n",
              "      <td>-0.716543</td>\n",
              "      <td>-0.358055</td>\n",
              "      <td>-1.156855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.493587</td>\n",
              "      <td>-0.962834</td>\n",
              "      <td>-0.685709</td>\n",
              "      <td>-0.543603</td>\n",
              "      <td>-0.503985</td>\n",
              "      <td>-0.708685</td>\n",
              "      <td>-0.622235</td>\n",
              "      <td>-1.024614</td>\n",
              "      <td>-1.225219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.488596</td>\n",
              "      <td>-0.934746</td>\n",
              "      <td>0.029585</td>\n",
              "      <td>-0.574389</td>\n",
              "      <td>-0.717949</td>\n",
              "      <td>-0.667131</td>\n",
              "      <td>-0.682487</td>\n",
              "      <td>-0.278017</td>\n",
              "      <td>-1.151662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.488596</td>\n",
              "      <td>-0.944109</td>\n",
              "      <td>-0.288323</td>\n",
              "      <td>0.124039</td>\n",
              "      <td>0.337607</td>\n",
              "      <td>0.367307</td>\n",
              "      <td>0.349657</td>\n",
              "      <td>-0.629004</td>\n",
              "      <td>-1.078971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.483605</td>\n",
              "      <td>-0.372985</td>\n",
              "      <td>0.983311</td>\n",
              "      <td>-0.838597</td>\n",
              "      <td>-0.879611</td>\n",
              "      <td>-0.928835</td>\n",
              "      <td>-0.894679</td>\n",
              "      <td>-1.138646</td>\n",
              "      <td>-1.372333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.483605</td>\n",
              "      <td>-0.944109</td>\n",
              "      <td>0.426971</td>\n",
              "      <td>0.988804</td>\n",
              "      <td>1.514411</td>\n",
              "      <td>1.510494</td>\n",
              "      <td>1.457772</td>\n",
              "      <td>-0.891376</td>\n",
              "      <td>-1.286661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.478614</td>\n",
              "      <td>-0.372985</td>\n",
              "      <td>1.380697</td>\n",
              "      <td>-0.523845</td>\n",
              "      <td>-0.544401</td>\n",
              "      <td>-0.564571</td>\n",
              "      <td>-0.598658</td>\n",
              "      <td>-0.884746</td>\n",
              "      <td>-1.375794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35a4a362-ec7d-4342-8375-a3541367ed76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35a4a362-ec7d-4342-8375-a3541367ed76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35a4a362-ec7d-4342-8375-a3541367ed76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0   2.623352 -0.672591           -1.083095     1.366966        1.771168   \n",
              "1   2.543496 -0.574283           -0.765186     2.303412        3.240388   \n",
              "2   2.498578 -0.906658           -0.924141    -0.880871       -0.865347   \n",
              "3   2.493587 -0.930065           -1.162572    -0.522007       -0.477834   \n",
              "4   2.493587 -0.962834           -0.685709    -0.543603       -0.503985   \n",
              "5   2.488596 -0.934746            0.029585    -0.574389       -0.717949   \n",
              "6   2.488596 -0.944109           -0.288323     0.124039        0.337607   \n",
              "7   2.483605 -0.372985            0.983311    -0.838597       -0.879611   \n",
              "8   2.483605 -0.944109            0.426971     0.988804        1.514411   \n",
              "9   2.478614 -0.372985            1.380697    -0.523845       -0.544401   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0   -0.362989   -0.072107      -1.251624           -1.213104  \n",
              "1   -0.262197   -0.095684      -1.079867           -1.098875  \n",
              "2   -0.965969   -1.002085      -1.168851           -1.050414  \n",
              "3   -0.805056   -0.716543      -0.358055           -1.156855  \n",
              "4   -0.708685   -0.622235      -1.024614           -1.225219  \n",
              "5   -0.667131   -0.682487      -0.278017           -1.151662  \n",
              "6    0.367307    0.349657      -0.629004           -1.078971  \n",
              "7   -0.928835   -0.894679      -1.138646           -1.372333  \n",
              "8    1.510494    1.457772      -0.891376           -1.286661  \n",
              "9   -0.564571   -0.598658      -0.884746           -1.375794  "
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "housing_df = pd.concat([housing_train_df, housing_test_df], ignore_index = True)\n",
        "housing_df = (housing_df - housing_df.mean()) / housing_df.std() \n",
        "\n",
        "housing_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn3xgs9VNihx",
        "outputId": "6c155843-00c9-4be2-e5be-fc1e2bb09108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total 20000, Training: 16000, Testing: 4000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "housing_train_df, housing_test_df = train_test_split(housing_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Total {len(housing_df)}, Training: {len(housing_train_df)}, Testing: {len(housing_test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y08VRcFGOVIj"
      },
      "source": [
        "## Construct Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "u0IBXNCjOKVK"
      },
      "outputs": [],
      "source": [
        "class HousingDataset(Dataset): # inherit Dataset\n",
        "\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    row = self.dataframe.iloc[index].to_numpy().astype('float32') # using index to locate a data row\n",
        "    features = row[0:-1] # get all columns except last one\n",
        "    label = row[-1] # last column => we want to predict\n",
        "    return features, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "KjVgB8VFObbd"
      },
      "outputs": [],
      "source": [
        "setup_seed(8888)\n",
        "\n",
        "train_dataset = HousingDataset(housing_train_df.astype('float32'))\n",
        "test_dataset = HousingDataset(housing_test_df.astype('float32'))\n",
        "\n",
        "train_batch_size = int(len(train_dataset))\n",
        "test_batch_size = int(len(test_dataset))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = train_batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = test_batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21uvrI4FOjPM",
        "outputId": "39b8812f-8dc2-467c-941b-5e67ed0780ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15l6wel2OyVu"
      },
      "source": [
        "## SLFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "4o_ldOndOxzK"
      },
      "outputs": [],
      "source": [
        "class SLFN(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, D_in, H, D_out, activation_func, initial_weights = None):\n",
        "    super(SLFN, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(D_in, H)\n",
        "    self.fc2 = torch.nn.Linear(H, D_out)\n",
        "    self.bn1 = torch.nn.BatchNorm1d(H) # batch normalization => normalize between fc and activation func\n",
        "    self.dropout = torch.nn.Dropout(p=0.5) # inverted drop out\n",
        "    \n",
        "    self.activation_func = activation_func\n",
        "    if activation_func == 'ReLU':\n",
        "      self.relu = torch.nn.ReLU()\n",
        "    if activation_func == 'Tanh':\n",
        "      self.tanh = torch.nn.Tanh()\n",
        "\n",
        "    self.initial_weights = initial_weights\n",
        "    if self.initial_weights == 'small random number':\n",
        "      # H = W * X + B ; X = D_in => linear algebra\n",
        "      # D_in (1, D_in), W (D_in, H)\n",
        "      self.fc1.weight = torch.nn.Parameter(0.01 * torch.FloatTensor(np.random.randn(H, D_in)))\n",
        "      self.fc2.weight = torch.nn.Parameter(0.01 * torch.FloatTensor(np.random.randn(D_out, H)))\n",
        "    if self.initial_weights == 'Xavier':\n",
        "      torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "      torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "    if self.initial_weights == 'Kaiming':\n",
        "      torch.nn.init.kaiming_uniform_(self.fc1.weight)\n",
        "      torch.nn.init.kaiming_uniform_(self.fc2.weight)\n",
        "  \n",
        "  def forward(self, x): # input\n",
        "    fc1 = self.fc1(x) \n",
        "\n",
        "    # activation\n",
        "    activation = None\n",
        "    if self.activation_func == 'ReLU':\n",
        "      activation = self.relu(fc1)\n",
        "    if self.activation_func == 'Tanh':\n",
        "      activation = self.tanh(fc1)\n",
        "    \n",
        "    pred = self.fc2(activation) \n",
        "    return pred\n",
        "\n",
        "  # inverted drop out (don't affect at testing phase)\n",
        "  def forward_do(self, x):\n",
        "    fc1 = self.fc1(x)\n",
        "    do1 = self.dropout(fc1)\n",
        "\n",
        "    # activation\n",
        "    activation = None\n",
        "    if self.activation_func == 'ReLU':\n",
        "      activation = self.relu(fc1)\n",
        "    if self.activation_func == 'Tanh':\n",
        "      activation = self.tanh(fc1)\n",
        "\n",
        "    pred = self.fc2(activation) \n",
        "    return pred\n",
        "\n",
        "  # input -> FC1 -> BN1 -> ReLU -> FC2 -> output\n",
        "  def forward_bn(self, x): # input\n",
        "    fc1 = self.fc1(x) \n",
        "    bn1 = self.bn1(fc1) \n",
        "\n",
        "    # activation\n",
        "    activation = None\n",
        "    if self.activation_func == 'ReLU':\n",
        "      activation = self.relu(bn1)\n",
        "    if self.activation_func == 'Tanh':\n",
        "      activation = self.tanh(bn1)\n",
        "    \n",
        "    pred = self.fc2(activation) \n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "oNEYGky3iTUP"
      },
      "outputs": [],
      "source": [
        "D_in = len(housing_train_df.columns) - 1 \n",
        "D_out = 1 \n",
        "hidden_nodes = [5, 8, 11] \n",
        "learning_rate = 1e-4 \n",
        "loss_fn = torch.nn.MSELoss().to(device) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJVN3xZ1O87l"
      },
      "source": [
        "## Weight Tuning EB and Regularizing EB\n",
        "We only show regularizing algorithm </br>\n",
        "<img\n",
        "width=\"600px\"\n",
        "src=\"https://lh3.googleusercontent.com/fife/APg5EOYOXcEzwpZUa-FLsXeR6yMrJ5rBcorGJm1VsaPjEF5gQYWzduPuyIx57aKhJ0-MY5feL2NlTm-DvXXEqApk9DQ9DBQVM7Ue6urUwcBG9499VknBAfKf18x0JY3mjT2B4pcFqY-zqeUDtj8f3inLFFSmqio1Gwk-IelGawU4YSZYB3DNsJ55OyEH5atm7Qn4_lFxh_79kXGa3SD-j9VQmiMWcJGnf0QxOKWq8D5dmecd5XIldK_xGbIQGug0hObWijKU6Q6C-vTIk8rM85qTx6NEzau-mOKAP0m0BwhcmiwWAUeDzdayUVTJZ6PzyITXbTTbGbJRcVTxzmiYYsaK6tvs1YMdfdJZoLVlRuXRpQLX0BxQrPL0pAxgP3J1ty-WSZXrd1aAcdKgs5TOdHWtkac-NBVTv4MQQYahX7O595IIdkNSawJ0JykDYC9KcY0tKXH9NkKPGq2TwlIn5KHuUYoCz0ztSAIziHF2HqWPqGxHhDnYDG8bgITMRP-P6-czrwPUaFB0FjSq-3KDmfkoCf7kWH7owyhE1aOckgmiw4zdY1n6qXZPEipj5WD_hSG2zoibeuvdVGZmbasAehh6J7RHKQn1U4Q09cBN15Z2Vkl6xulV2rR6poGV5NIft5YuOJIwNvRSuAaEFzwGN8vpapqTKdcCbrrAfD7u4VHD1Wnej00pbwNZQKzJRWVrP0BvySR2uOu696M3IvtTW8bPNMMqECpIMX72qqRGtofr_emyoPr_YQMt0dDuZ7jYpFzI3CFAWRpmXLdfAAHnfuuLtaOYhv6rD-2DoHJOCTelW2oXx614DHH2e03qD_fGhLpZ3aCAUGGFKhdUvRWoS0aWCx4p4UbW1SLTanmuxdqVue8QyQY9B6Bpxl1QeQe3ZvbuzFskY4IDPlP8AvI13QEN4d8CcMEhZH7155KmBPUGGpZGekw2xx0Ns5KNyB5mXIjVnIraYwhW1fX8rbLdvKcWw53Mpeo2BsS5STdIKEQjNEr1xT54o0giiQmKiRIklDnYOi8HPaRQ_WK-icof1dlTCFUKd9KBwnzQRp-be_N-X1F5y05oABPq0Egb2yF_OIPXhVbUWYKw4OC8fBYbrnG9TgXfMwL26Su5AvKH9l2L2_wwMD4NCtUbSlck1T9OWWhhow8XD-4LeOULKNp5mjEZy_2dJvD57dtoU2KIrrMM8KjD02Ujf2ZVHPc_9fdhmF_l-0tT0T6DsMr_dU6xNU95JIGgm-prmRbP28LHLPrhweASm8cljKgynbYqJvZueKDRq6Z7AwTiVlH3A3M-ZiMCzEIMit9mDcn1-ms9_HBNRa8p-h-ZGQMw9v7r7Zit1l3XIeHu_9rZb2BzLHNKLvFDgQVE4c_VuIJC7VsI1iLp5313UgOBrgSfEmgNBNsAX7TYJSOiPxMbvqY5F63AGWL790UNWeXWNKDINR6NI6WcApe-OTeM2T-d4J8BkRA3fcOulP-m4Yjmd6uqulUZKx3BVGjOfFlzyqsFdsA8bcTYb8RuM9SNs4jxHIlG4z-ssDE6mvMevmBJLbepIIxOW1HcPmWWg9VSe8nQs9zMbQUH6rqhgb-KklaUhS8_6XrbcGgLJXc=w1466-h1622\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5jWEw_7O0Su"
      },
      "source": [
        "### Weight Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Y4tcJldXO1hP"
      },
      "outputs": [],
      "source": [
        "setup_seed(8888)\n",
        "epoch_bound = 100 # EB\n",
        "epsilon = 0.995 # LG\n",
        "\n",
        "model_EB_LG = SLFN(D_in, hidden_nodes[1], D_out, 'ReLU', 'small random number').to(device)\n",
        "optimizer_EB_LG = torch.optim.Adam(model_EB_LG.parameters(), lr = learning_rate) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ6APzB3jCgS",
        "outputId": "1ba4b79b-6bf5-4dbb-e9c9-72d4267718e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "loss: 0.9986434578895569\n",
            "----------------------\n",
            "10\n",
            "loss: 0.9983462691307068\n",
            "----------------------\n",
            "20\n",
            "loss: 0.9980566501617432\n",
            "----------------------\n",
            "30\n",
            "loss: 0.9977754950523376\n",
            "----------------------\n",
            "40\n",
            "loss: 0.9975031614303589\n",
            "----------------------\n",
            "50\n",
            "loss: 0.9972395896911621\n",
            "----------------------\n",
            "60\n",
            "loss: 0.9969844818115234\n",
            "----------------------\n",
            "70\n",
            "loss: 0.9967378973960876\n",
            "----------------------\n",
            "80\n",
            "loss: 0.9964994788169861\n",
            "----------------------\n",
            "90\n",
            "loss: 0.9962692260742188\n",
            "----------------------\n",
            "100th epoch\n",
            "loss: 0.9960691332817078\n",
            "Unaccetable SLFN!\n"
          ]
        }
      ],
      "source": [
        "t = 0\n",
        "loss = np.inf\n",
        "\n",
        "while t < epoch_bound and loss > epsilon:\n",
        "  for batch, (X, y) in enumerate(train_dataloader): \n",
        "    # forward \n",
        "    pred = model_EB_LG(X.to(device))\n",
        "    loss = loss_fn(pred, y.to(device))\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "    optimizer_EB_LG.step()\n",
        "    optimizer_EB_LG.zero_grad()\n",
        "\n",
        "  if t % 10 == 0:\n",
        "    print(f\"{t}\")\n",
        "    print(f\"loss: {loss}\")\n",
        "    print(\"----------------------\")\n",
        "\n",
        "  t+=1\n",
        "\n",
        "print(f\"{t}th epoch\")\n",
        "print(f\"loss: {loss}\")\n",
        "if loss < epsilon:\n",
        "  print(\"Accetable SLFN!\")\n",
        "else:\n",
        "  print(\"Unaccetable SLFN!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPBc8ntpO2AI"
      },
      "source": [
        "### Regularizing - Epoch Bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nH2ijGuO5BT",
        "outputId": "e79dd1d7-43fa-4f21-95b7-d8a4941ed5ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{Parameter containing:\n",
              " tensor([[-4.1122e-03, -4.9928e-04,  1.8260e-03,  2.4875e-02,  1.7346e-03,\n",
              "          -1.1060e-02, -6.0659e-03,  9.4524e-04],\n",
              "         [ 1.1628e-02,  2.7409e-03,  1.3594e-02,  7.5668e-03, -1.7076e-02,\n",
              "           2.4890e-03,  1.0393e-02,  7.6131e-03],\n",
              "         [-1.0846e-02,  1.9589e-03, -1.1032e-02,  1.0573e-02,  1.6618e-02,\n",
              "          -7.0028e-03,  1.0204e-03, -4.5638e-03],\n",
              "         [-1.0389e-02, -2.1280e-02,  5.9019e-03, -8.4633e-03, -7.5374e-03,\n",
              "           1.3749e-03,  6.5155e-03, -4.1925e-03],\n",
              "         [-7.7539e-03,  5.6415e-03, -7.1718e-03, -1.2726e-02, -2.4334e-03,\n",
              "           7.9423e-03,  1.0855e-03,  1.2128e-02],\n",
              "         [-1.5914e-02, -1.1129e-02, -3.4936e-02, -1.3797e-02,  4.1254e-03,\n",
              "          -4.8289e-03,  1.0431e-02,  1.2035e-02],\n",
              "         [-8.8780e-03,  8.2943e-03, -1.0354e-02, -9.1499e-03, -3.8567e-03,\n",
              "           1.4116e-02, -6.6725e-03,  4.8900e-05],\n",
              "         [ 2.5719e-02,  1.3290e-02,  5.1604e-03, -3.4849e-03, -8.3781e-03,\n",
              "           8.0108e-03, -9.7810e-03,  1.2596e-03]], requires_grad=True): Parameter containing:\n",
              " tensor([[-4.1122e-03, -4.9928e-04,  1.8260e-03,  2.4875e-02,  1.7346e-03,\n",
              "          -1.1060e-02, -6.0659e-03,  9.4524e-04],\n",
              "         [ 1.1628e-02,  2.7409e-03,  1.3594e-02,  7.5668e-03, -1.7076e-02,\n",
              "           2.4890e-03,  1.0393e-02,  7.6131e-03],\n",
              "         [-1.0846e-02,  1.9589e-03, -1.1032e-02,  1.0573e-02,  1.6618e-02,\n",
              "          -7.0028e-03,  1.0204e-03, -4.5638e-03],\n",
              "         [-1.0389e-02, -2.1280e-02,  5.9019e-03, -8.4633e-03, -7.5374e-03,\n",
              "           1.3749e-03,  6.5155e-03, -4.1925e-03],\n",
              "         [-7.7539e-03,  5.6415e-03, -7.1718e-03, -1.2726e-02, -2.4334e-03,\n",
              "           7.9423e-03,  1.0855e-03,  1.2128e-02],\n",
              "         [-1.5914e-02, -1.1129e-02, -3.4936e-02, -1.3797e-02,  4.1254e-03,\n",
              "          -4.8289e-03,  1.0431e-02,  1.2035e-02],\n",
              "         [-8.8780e-03,  8.2943e-03, -1.0354e-02, -9.1499e-03, -3.8567e-03,\n",
              "           1.4116e-02, -6.6725e-03,  4.8900e-05],\n",
              "         [ 2.5719e-02,  1.3290e-02,  5.1604e-03, -3.4849e-03, -8.3781e-03,\n",
              "           8.0108e-03, -9.7810e-03,  1.2596e-03]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.1629,  0.2961, -0.0405,  0.1810,  0.1347, -0.3430, -0.2264,  0.1713],\n",
              "        requires_grad=True): Parameter containing:\n",
              " tensor([ 0.1629,  0.2961, -0.0405,  0.1810,  0.1347, -0.3430, -0.2264,  0.1713],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0038,  0.0009,  0.0019,  0.0038,  0.0154, -0.0116, -0.0129,  0.0054]],\n",
              "        requires_grad=True): Parameter containing:\n",
              " tensor([[-0.0038,  0.0009,  0.0019,  0.0038,  0.0154, -0.0116, -0.0129,  0.0054]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0785], requires_grad=True): Parameter containing:\n",
              " tensor([-0.0785], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True): Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True): Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)}"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "setup_seed(8888)\n",
        "\n",
        "# store weight first\n",
        "original_param = {}\n",
        "for param in model_EB_LG.parameters():\n",
        "  original_param[param] = param\n",
        "\n",
        "original_param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "IC3cpvLkoT5r"
      },
      "outputs": [],
      "source": [
        "# define loss function with regularization term (L2 regularizing)\n",
        "# using weight decay in pytorch\n",
        "# or simply add regularization term in training phase\n",
        "# tutorial: https://androidkt.com/how-to-add-l1-l2-regularization-in-pytorch-loss-function/\n",
        "optimizer_EB_r = torch.optim.Adam(model_EB_LG.parameters(), lr = learning_rate, weight_decay=0.001) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at7Zz7mAnD1Z",
        "outputId": "6cd540a2-407d-4bc9-a5e4-7799f8f702dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16000])) that is different to the input size (torch.Size([16000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "loss: 0.9986435174942017\n",
            "----------------------\n",
            "10\n",
            "loss: 0.9983468055725098\n",
            "----------------------\n",
            "20\n",
            "loss: 0.9980581998825073\n",
            "----------------------\n",
            "30\n",
            "loss: 0.9977777600288391\n",
            "----------------------\n",
            "40\n",
            "loss: 0.997505784034729\n",
            "----------------------\n",
            "50\n",
            "loss: 0.9972425699234009\n",
            "----------------------\n",
            "60\n",
            "loss: 0.9969879984855652\n",
            "----------------------\n",
            "70\n",
            "loss: 0.9967420697212219\n",
            "----------------------\n",
            "80\n",
            "loss: 0.9965041279792786\n",
            "----------------------\n",
            "90\n",
            "loss: 0.9962746500968933\n",
            "----------------------\n",
            "loss: 0.9960530996322632\n",
            "Unacceptable SLFN!\n"
          ]
        }
      ],
      "source": [
        "for i in range(epoch_bound):\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    pred = model_EB_LG(X.to(device))\n",
        "    loss = loss_fn(pred, y.to(device))\n",
        "    loss.backward()\n",
        "    optimizer_EB_r.step()\n",
        "    optimizer_EB_r.zero_grad()\n",
        "\n",
        "  if i%10 == 0:\n",
        "    print(f\"{i}\")\n",
        "    print(f\"loss: {loss}\")\n",
        "    print(\"----------------------\")\n",
        "\n",
        "# check if loss become smaller\n",
        "for batch, (X, y) in enumerate(train_dataloader):\n",
        "  pred = model_EB_LG(X.to(device))\n",
        "  loss = loss_fn(pred, y.to(device))\n",
        "\n",
        "  print(f\"loss: {loss}\")\n",
        "  if loss < epsilon:\n",
        "    print(\"Acceptable SLFN!\")\n",
        "  else:\n",
        "    # restore w\n",
        "    for param in model_EB_LG.parameters():\n",
        "        param = original_param[param]\n",
        "\n",
        "    print(\"Unacceptable SLFN!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi4i-8zXDGXY",
        "outputId": "ad5674b7-67e8-4f93-ca75-b4a58cb93a9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-5.8515e-04, -4.0529e-04,  5.3400e-04,  1.5782e-02, -1.5714e-04,\n",
              "          -3.0158e-03, -2.5888e-04, -1.6293e-03],\n",
              "         [ 2.9953e-03, -3.6691e-04,  5.4048e-03, -1.0521e-03, -8.5010e-03,\n",
              "          -3.4984e-03,  2.1135e-03, -7.4957e-04],\n",
              "         [-2.3132e-02,  1.6143e-02, -2.4707e-02,  2.3572e-02,  2.9644e-02,\n",
              "           5.7535e-03,  1.3878e-02,  9.4470e-03],\n",
              "         [-3.5210e-03, -1.2071e-02,  9.8798e-04, -3.0500e-03, -1.1508e-03,\n",
              "          -3.9110e-03, -1.7468e-03, -4.0492e-03],\n",
              "         [-4.0122e-03,  5.3402e-04,  1.4281e-03, -7.1565e-03,  1.9483e-03,\n",
              "           7.4330e-04,  3.7719e-03,  3.2281e-03],\n",
              "         [-7.2030e-03, -3.1051e-03, -2.5467e-02, -5.3232e-03, -3.0235e-05,\n",
              "           4.5297e-05,  2.5692e-03,  3.8326e-03],\n",
              "         [-1.4798e-03,  1.1196e-03, -2.5118e-03, -1.6580e-03,  1.2815e-05,\n",
              "           5.6011e-03, -3.2717e-04,  2.2905e-07],\n",
              "         [ 1.6156e-02,  5.1461e-03,  1.0652e-03, -1.8373e-03, -1.7909e-03,\n",
              "          -2.4108e-03, -2.8480e-03, -4.8960e-03]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.1611,  0.3060, -0.0273,  0.1928,  0.1451, -0.3330, -0.2165,  0.1827],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0056,  0.0105,  0.0149,  0.0134,  0.0251, -0.0035, -0.0046,  0.0150]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0690], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[para for para in model_EB_LG.parameters()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7hZzW_ZPPwn"
      },
      "source": [
        "## Weight Tuning EB and Regularizing DO\n",
        "<img\n",
        "width=\"600px\"\n",
        "src=\"https://lh3.googleusercontent.com/fife/APg5EOYC0ll8hGHIiZfY_M_LwGljkHaznZiy3NsR3eRLTTBzLN2iTVLRbjYNC7qYTde627GD7FFL8pbEvIqt7SAfxPYLJcEmjQTlLCLE21cH1Bx9uX-pJs-qqr4RmHYj-b5hFAxOCf7FNXyxMzhLnMW1k9CH6ifMFhSe01Eh_pO3Wznx3ThwsTugJxCU9WwBhbL88QMl_U0tYayVLvrM7k5L8SbKT7nr7ZdwEmnJXqLBeNgyW21AjsCH10zVBLn09fsh0M5O-teFgbj2ubcARzwXErmYXGf0LXVpPZOdD_5O--ennLAvE72SNqeMBSpxSh-t9g9jVmANcxQrLZsOMyLWe3IAiI8ksDYmHYwY7VetKLivIq3vEdlHka4jXx0R0rW2AYVo__L5g086QU3SQQ9lXNMhbYJf8SaVIzImFoCslr03olYFKn5ZDSTW-Od-c4B3RHxrlIwBJ8or-XLwtPpWMRypuMQzYLEXtjXXNmKxDof7UsLvDjHVMaTAkqhU762Xqs4pIHtL55sC2kE6WA-SlKbBR_EU2_nmX8EgfJXGSbppeGud5KYXFZOrOvrDLo1mNZyObCxpauiI8Kp_zrmvbs6qHvKhm5ZuEIan0EX-pqggdGO6DOnsnqv0a4W9NICoJSQJmTBUipEmQ04gNvUsbNcHAsf4julAFwJF9nMC4nE4wHX0RX2geFgl-N3UgvGluTDpC0_MUEO9242g0BBp9YN42xO1gUcOI57AJeaLFRQlhs3IIe6OUGxMwhojnPR_0hhHrivsJnlHOKqQ3Dk4fJ5-MWN5r7YMatlu3f8Dcgb9FDu2pdiabiBPE089mo_nhqKGuI4szwGvA21uIVHXEqZoBW06Kz1BmDO32JzC07tldQmU3jHt43qK7qh-bXzlkcRMsbl3hxTxLZXu6ilBPSbaYJOXWKZy7jknNajypqAbvEmLkrtdsy3f6tS1KM5tcT4muvg5Yt_TyXroChEgwp805NCRXGK4ipQ5hT5sXF1sUh9xsACPfepTbRTQI8pqJ6boSMWW2nGihFd22TDNc7gts_WluF2je2H7iAtT4f7Sq6pL0FxS_n8WfVeY9EXy1Dm9G7X2Iz1JrOl40N7QOhHR-uDCk8gvEJ6YGWCa5r2OBxFEl6dbOnfrFKRwdpRO58JuDbto9bp0vmEs3WSK65EaVQMvVOuKquQ6KRTzpMaWH_HwsdHqxPUZP9p8DVIizcmCSeUUMboNuvN-sw_Ko0a5-EtHDKPzORaHkrSIjHHz8DPWifbX3y4xL98mtrwyAqJFmDwee0k-zK5NtXvif-sABZun7s9_mk4-T4jorB5TOvEZ_UrkcuhiVW7TeyoNgQtrRoG5wBMQe6jc8tczU7-9rVtawDgSs8GahrHLZVFzk8nzBSXRlkN8Jm_K1nCZPu3is7-CWWciIDWqYhhhVk04PwfA2qSfzYbCNZkfPULQUNBE531LxJTlRJLD560FIVntJr5lJAuZYhuVE_qkf1yUqQPaSrLN44k9LeulwSls01gISswztJqRa-g26Tcn-UroOY1794CPJw4Xiy4OEaFEu-tIGy9-guOLGmjHRlrSt9xeR5By37_4puruntPepxo=w1466-h1654\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v15xrIGLDIQl"
      },
      "source": [
        "### Regularizing - Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om5Q1SYIPTj8",
        "outputId": "53a58550-6002-45fd-b033-8597183caf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "loss: 0.996053159236908\n",
            "----------------------\n",
            "10\n",
            "loss: 0.9958193898200989\n",
            "----------------------\n",
            "20\n",
            "loss: 0.9955945014953613\n",
            "----------------------\n",
            "30\n",
            "loss: 0.9953791499137878\n",
            "----------------------\n",
            "40\n",
            "loss: 0.9951740503311157\n",
            "----------------------\n",
            "50\n",
            "loss: 0.9949794411659241\n",
            "----------------------\n",
            "60\n",
            "loss: 0.9947953820228577\n",
            "----------------------\n",
            "70\n",
            "loss: 0.9946216344833374\n",
            "----------------------\n",
            "80\n",
            "loss: 0.9944584369659424\n",
            "----------------------\n",
            "90\n",
            "loss: 0.9943054914474487\n",
            "----------------------\n",
            "loss: 0.9941623210906982\n",
            "Acceptable SLFN!\n"
          ]
        }
      ],
      "source": [
        "# use forward dropout mode\n",
        "for i in range(epoch_bound):\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    pred = model_EB_LG.forward_do(X.to(device))\n",
        "    loss = loss_fn(pred, y.to(device))\n",
        "    loss.backward()\n",
        "    optimizer_EB_LG.step()\n",
        "    optimizer_EB_LG.zero_grad()\n",
        "\n",
        "  if i%10 == 0:\n",
        "    print(f\"{i}\")\n",
        "    print(f\"loss: {loss}\")\n",
        "    print(\"----------------------\")\n",
        "\n",
        "# check if loss become smaller\n",
        "for batch, (X, y) in enumerate(train_dataloader):\n",
        "  pred = model_EB_LG(X.to(device)) # still use normal dropout => inverted dropout\n",
        "  loss = loss_fn(pred, y.to(device))\n",
        "\n",
        "  print(f\"loss: {loss}\")\n",
        "  if loss < epsilon:\n",
        "    print(\"Acceptable SLFN!\")\n",
        "  else:\n",
        "    # restore w\n",
        "    for param in model_EB_LG.parameters():\n",
        "        param = original_param[param]\n",
        "\n",
        "    print(\"Unacceptable SLFN!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clei5VVOO2Y_",
        "outputId": "2ee94efd-8db6-4146-d00d-c5a31e84bab1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 8.7154e-04, -1.0713e-02, -9.1022e-03,  6.4833e-03,  8.2373e-03,\n",
              "          -6.5233e-03,  8.3411e-03,  2.8763e-03],\n",
              "         [ 4.1791e-03, -1.0149e-02, -3.7945e-03, -9.5022e-03, -6.1113e-04,\n",
              "          -6.7911e-03,  1.0218e-02,  3.0127e-03],\n",
              "         [-3.3584e-02,  2.6573e-02, -3.4950e-02,  3.3712e-02,  3.9762e-02,\n",
              "           1.5879e-02,  2.4004e-02,  2.0204e-02],\n",
              "         [-1.6503e-02, -1.3180e-02,  1.2855e-02, -1.7293e-02, -1.5532e-02,\n",
              "          -1.8041e-02, -1.6131e-02, -1.3932e-02],\n",
              "         [-3.1573e-03, -8.7334e-03, -7.3155e-03, -1.4837e-02,  9.3486e-03,\n",
              "          -2.3929e-03,  1.1393e-02,  6.2914e-03],\n",
              "         [-7.2030e-03, -3.1051e-03, -2.5467e-02, -5.3232e-03, -3.0235e-05,\n",
              "           4.5297e-05,  2.5692e-03,  3.8326e-03],\n",
              "         [-1.4798e-03,  1.1196e-03, -2.5118e-03, -1.6580e-03,  1.2815e-05,\n",
              "           5.6011e-03, -3.2717e-04,  2.2905e-07],\n",
              "         [ 3.9446e-03,  2.9420e-03,  1.2466e-02, -1.6105e-02, -1.5797e-02,\n",
              "          -1.6670e-02, -1.6865e-02, -1.4723e-02]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.1721,  0.3163, -0.0167,  0.2030,  0.1549, -0.3330, -0.2165,  0.1927],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0150,  0.0198,  0.0252,  0.0227,  0.0344, -0.0035, -0.0046,  0.0244]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0597], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[para for para in model_EB_LG.parameters()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM4uJXMvPERY"
      },
      "source": [
        "## Weight Tuning EB and Regularizing BN\n",
        "<img\n",
        "width=\"600px\"\n",
        "src=\"https://lh3.googleusercontent.com/fife/APg5EOZWqgUCaWuJEXYB_u2gNydfsuVESMdw8e7xDekXvUvJadbuatMTygf8vaCge_kQMijMXh4eQ8s_YXeoCZLWIQb3v7-uNr3CEeaVzgVgml4HVskAkGIedo5D6UawqAwj5h3JIYjvEXFrDT1PuLoXaLYYH3cdUsXUmCaIQEvGq4LUIsaieIxBeK7IUNbxUo0kHP4G0DIyw6r4FVS47eB4qZ6ld0vi-oztLmsgdCvLoTVWuEMczjDSqDkTYFVcXyAz1V36teZu_X_tldYGuPPiak_TLAhSxdPPRUmn6Q4uk3RHy8LLpsVdxQprGLscrfhyooRzpaPrvbww3aWvlAvvJIKgpJrA-i2VEqZ80_uzy63K2QCXtCrf8nB1qzpoZ0BkaNFsR861jQPIBVPBc_3VHu6x5uS1krCGYGJ0gOYVUanYifwMNf3_0axjXLMTGKlXT3dv--f43iKS42u_CCdOPS-m-L-1uWQZ9MnIGfaFy_royFQJfRN9IBg1sLAqqVWEaljUN-0v5gmCSIK_JZofJ_uKZqzlYeXt39mnS5j1uyTDstR4dCtUK_9_nj2K1gs0BvNDI84lIkp-jTwfJY1GFYsLkGqk-IT8QwxyIH3nUZRf1tjjMf2Otlhjqk6tnQo0WGEsljXFqcaIb_2GCjeFypoIYaiHaBM9-FjXu9JfU084LMJ88ZsKLrZs7f67_xYdi07jJkvBm4AbWPpu93bE0krhebc5MHo3xDOYwzM5D_E4Z8IbISLo-aOwOLkgAkEFhMg7IFW7XDlzBT61jxZXCIMnElT7derFfOcQl5eFmF8JSPtXAlys_pVDJJSedoZkCOZDQZwERR_kLOd6-IOFhUMSJUxX3TxmTuy3iFiqxR1ih3dblXtyAqFZ_leH3Nd5kyuW15W36PONtfHlH_y3zS4T2JaSAaGrkHhayvPccmxATRuR7yuM0Z9_milcDzrEyyjUv3ZtYHn2EZvE7p0DPClLWXx3IPzSnn0L9Aa5breswa1R3ouQas3Eg6jzbrourM8dU5uo8AVtVaQ5BdZT9LrFupzEe0j6m6bdbmjKOkj6WZBMEG2dk36Bp7VZJFArK96gkwt21VzxfkzztdC0pQir5lvFb3sSqdM4ktIfM9SFq7XksVKQIccWObhF-oyBJ-AGFMh4kRojcXtT6vcyIPwyKBhp2IXtbnFay1SOtydxoTFGcrbw5TUbkgj9TyT575XshKQONM_BD0N-T3H2sTVsR3dTIWgDzVWz1fvyEPSkuGUrfBuq6jfPEas5qRt6dDka75mOck6uN1NzaVnLZtb4rJWbbsn78S8bnmvID0DJqqgay7t2-IJhhFtbDUW_0uixjxgnYMrWIUPUEeZy8o89T5Ah5In_wMzn4qQCF0u0XJuuDx78JhzU0Qm5Tibb7Z7izv5HPCeRJDFmOpyVRogBR63j6yNDNMx9r2hm4gSSqwUB9SiZst5HSR1dJmvd60v1EZTS6b5GX9DpOBrcrQUSVTNS_cCNBqkTM0yCZZgIWgeLBrLgfH3np3JHjAtwRtsbG0w_UorOSeJkfLeMOCyg3u2McjXu5rGtIH5tNZzYsXofc_XzKRPCFXZKIFr6E6o=w1466-h1654\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sdlpMPnE7ZP"
      },
      "source": [
        "### Regularizing - Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtCmLCkLE_uH",
        "outputId": "1938ffa9-e0c2-4103-ee96-812dd5a925a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "loss: 0.993184506893158\n",
            "----------------------\n",
            "10\n",
            "loss: 0.9931737780570984\n",
            "----------------------\n",
            "20\n",
            "loss: 0.9931650161743164\n",
            "----------------------\n",
            "30\n",
            "loss: 0.9931573867797852\n",
            "----------------------\n",
            "40\n",
            "loss: 0.9931507706642151\n",
            "----------------------\n",
            "50\n",
            "loss: 0.9931449294090271\n",
            "----------------------\n",
            "60\n",
            "loss: 0.9931395053863525\n",
            "----------------------\n",
            "70\n",
            "loss: 0.9931345582008362\n",
            "----------------------\n",
            "80\n",
            "loss: 0.993129551410675\n",
            "----------------------\n",
            "90\n",
            "loss: 0.9931249618530273\n",
            "----------------------\n",
            "loss: 0.9938995242118835\n",
            "Acceptable SLFN!\n"
          ]
        }
      ],
      "source": [
        "# use original model\n",
        "# use forward dropout mode\n",
        "for i in range(epoch_bound):\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    pred = model_EB_LG.forward_bn(X.to(device))\n",
        "    loss = loss_fn(pred, y.to(device))\n",
        "    loss.backward()\n",
        "    optimizer_EB_LG.step()\n",
        "    optimizer_EB_LG.zero_grad()\n",
        "\n",
        "  if i%10 == 0:\n",
        "    print(f\"{i}\")\n",
        "    print(f\"loss: {loss}\")\n",
        "    print(\"----------------------\")\n",
        "\n",
        "# check if loss become smaller\n",
        "for batch, (X, y) in enumerate(train_dataloader):\n",
        "  pred = model_EB_LG(X.to(device)) # still use normal dropout => inverted dropout\n",
        "  loss = loss_fn(pred, y.to(device))\n",
        "\n",
        "  print(f\"loss: {loss}\")\n",
        "  if loss < epsilon:\n",
        "    print(\"Acceptable SLFN!\")\n",
        "  else:\n",
        "    # restore w\n",
        "    for param in model_EB_LG.parameters():\n",
        "        param = original_param[param]\n",
        "\n",
        "    print(\"Unacceptable SLFN!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkr-tw5bO34l",
        "outputId": "c769c448-2353-45c0-e271-408eb73163bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0093, -0.0196, -0.0026,  0.0021,  0.0002, -0.0010,  0.0003, -0.0056],\n",
              "         [ 0.0134, -0.0190,  0.0058, -0.0079, -0.0021,  0.0025,  0.0089, -0.0037],\n",
              "         [-0.0417,  0.0346, -0.0541,  0.0237,  0.0270,  0.0053,  0.0112,  0.0211],\n",
              "         [-0.0291, -0.0030,  0.0091, -0.0031, -0.0058, -0.0009, -0.0011,  0.0003],\n",
              "         [ 0.0059, -0.0202, -0.0037, -0.0156,  0.0056,  0.0006,  0.0082,  0.0153],\n",
              "         [ 0.0032, -0.0126, -0.0079, -0.0014,  0.0073,  0.0014,  0.0098,  0.0125],\n",
              "         [ 0.0033, -0.0032, -0.0024,  0.0006,  0.0047,  0.0026,  0.0040,  0.0077],\n",
              "         [-0.0032,  0.0124,  0.0089, -0.0158, -0.0118, -0.0011, -0.0114, -0.0236]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.1731,  0.3173, -0.0157,  0.2039,  0.1558, -0.3325, -0.2151,  0.1937],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0138,  0.0210,  0.0299,  0.0217,  0.0319, -0.0083, -0.0096,  0.0232]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0554], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.9980, 1.0014, 1.0030, 0.9931, 0.9963, 1.0024, 1.0031, 0.9927],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0151,  0.0191,  0.0146,  0.0095,  0.0144, -0.0176, -0.0179,  0.0095],\n",
              "        requires_grad=True)]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[para for para in model_EB_LG.parameters()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model_EB_LG, 'model_EB_LG.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNKrpzwhwgJuqN5NcwHorxN",
      "collapsed_sections": [
        "15l6wel2OyVu",
        "VM4uJXMvPERY"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
