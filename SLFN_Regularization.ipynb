{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mao-code/SLFN_Regularization/blob/main/SLFN_Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gH-VZtf4LqsW"
   },
   "source": [
    "# This is based on the HW4 of New Learning Algorithm class (To handle overfitting)\n",
    "Using regularizing module. Not just using weight_tuning_r </br>\n",
    "\n",
    "<img\n",
    "width=\"500px\"\n",
    "src=\"https://lh3.googleusercontent.com/fife/APg5EOZ3hBraPY_Aa_TvGC-NZDWh5IpjnJf6kCwI3NKKrgO3kswHjrAtc32_iiwHx_OiEylmWEvnKGSpU_XK-kLtIHu2u0JBpLiBIlEe0wueEsaqs2_Xtxsl_udgl6jW61Z2965WnmZZYFla7zyEgu6JSmd9P9H62NhRHpZgdpX95J7kmPmPcTyUxJa_Ua6FXJ9J2b_yrgpPN3x_6eA8wm8x2S8xS0A_dmbZbkbC0j_X1VKhvirgLfQygawq0uaaIf5FRE16xrBuSwQ7pZoj2Eyk_GO1YKbFaXjb3lsj8j05TjPHdTYC0S-xflbgKANERDNe6tG3MttAnhgPi32wAqgdbLYNqea3cV6vLgEyK9feGTQpioYgPTREj_idBef-Tz9ztFPUsHInV4yk1A92wgfFI73_3dCEwkifWp5Amdx2zyN0kNkmrdntOy6cMt7-hcf0UydEJ8rNSL5Vd8kzNIicCg-UjXYvplti6VNMk1n5HY7SVupD2FL_c8UUKZVApkDzTeh71lDGL8i5A1H-QMQGcXfrZjzpCamrHiMDJRFZi5NIvJ3A4fx25PjbMVhePhgzrazM62vlXRWcHww-U4wCMBn1wh2WTQ6Aa3mN8LOAdiw8j7abWfTpEoABI18KoanH7xs2AWPTFdxPCXHmwg3XieaTlBPU943WiRmMRblI2cMDxVsiBojUQ-jwXAlsEQDfYt_bHvFlHQfu5j_byjHXjhEZjPcAu0pAdDIMrYDogp9o2toDjJHy2f9ziuMOYayncA_DP5EgTJLjgG5AVaOABRDGmV07ar5FxEEhXpk9E07KNSTiERq2g3g2SIwnalP8wP9d7yRfzNNRwsqYjsNGs65g-4iEoGKjpZnlyTgXoHrKFv6MooeOkiucbe8MsIneNQ-vQraaxmJwvFTbsewz_XzIDZlxLWVyCdpzowvoJtlDhZL3XU6MgsuCsGIx1wDVC_Fg_1EpxHxXsvZDch1tnYHPq1QkEuKxn3goHSOUW4plGytXJp8PucPz0IyD8Pke47h0_9ryNgqChFa1ml7xZWTu57A_7UFaarwUUIAPAZaxpzdNw0y8Rz21YJWk32iTOi5t-kYT80XMQXzOvii4pTlov7QW2VQMJ0W_YCbh9bDCnJ7TyMt_SsKKb_KrLBZ6ZaCgFuuKao_0igHQeT6r_tsb5urljjikb2GyDvchuZbl4aPC-B5UnLK9HAyPzdw7hdHiKYyiO2wxKNbk9fDDwI8Gzgvd2TdxXhPIbX-s9SkKIb9B833448J1JXRPDlQvSXpXTfNSNQQlixV-XG1dhIrMSDCKu3iehUPOUXzGguMCTIKz_jVNZDfM5AnbgEaXBqLJDjVrNxNcvQdiH7WWxHKNR-IETCwXVlUMzUXlr4D8QRg9_xHvPF-HvxptVjPIuRmNpdXRnATisl9rjYlgC6j78qNlLrkYBHZVcCadZ87sDI-SyaE1HAE-m_tnLfm0uPFQ_2N9Bb8hG-0qVmmNQmSbfvcI5twSSXSsuTVhJ7thdPwiTLIk23ynGVzFyJJC1ZiiOl3L6T6zYB7EDBS5NoxjXNGqHY05A_xoOlHssvxllKvGP79U1IK2rhsff1WMUcY=w1912-h1566\"\n",
    "alt=\"HW4\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ce9rIzOFIRy-"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rlm4ms-NVJC"
   },
   "source": [
    "## Setup seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2ILlJF3YMatY"
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "   torch.manual_seed(seed)\n",
    "   torch.cuda.manual_seed(seed)\n",
    "   torch.cuda.manual_seed_all(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "   torch.backends.cudnn.benchmark = False\n",
    "   torch.backends.cudnn.deterministic = True\n",
    "   torch.backends.cudnn.enabled = True\n",
    "\n",
    "setup_seed(8888)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnKL2NwxNXSo"
   },
   "source": [
    "## Data constructing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jTbBHluyNOAO"
   },
   "outputs": [],
   "source": [
    "housing_train_df = pd.read_csv('sample_data/california_housing_train.csv')\n",
    "housing_test_df = pd.read_csv('sample_data/california_housing_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "Um09O5XoNe0z",
    "outputId": "b2a47cff-2a40-4206-bd4a-4519e323fa0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.623352</td>\n",
       "      <td>-0.672591</td>\n",
       "      <td>-1.083095</td>\n",
       "      <td>1.366966</td>\n",
       "      <td>1.771168</td>\n",
       "      <td>-0.362989</td>\n",
       "      <td>-0.072107</td>\n",
       "      <td>-1.251624</td>\n",
       "      <td>-1.213104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.543496</td>\n",
       "      <td>-0.574283</td>\n",
       "      <td>-0.765186</td>\n",
       "      <td>2.303412</td>\n",
       "      <td>3.240388</td>\n",
       "      <td>-0.262197</td>\n",
       "      <td>-0.095684</td>\n",
       "      <td>-1.079867</td>\n",
       "      <td>-1.098875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.498578</td>\n",
       "      <td>-0.906658</td>\n",
       "      <td>-0.924141</td>\n",
       "      <td>-0.880871</td>\n",
       "      <td>-0.865347</td>\n",
       "      <td>-0.965969</td>\n",
       "      <td>-1.002085</td>\n",
       "      <td>-1.168851</td>\n",
       "      <td>-1.050414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.493587</td>\n",
       "      <td>-0.930065</td>\n",
       "      <td>-1.162572</td>\n",
       "      <td>-0.522007</td>\n",
       "      <td>-0.477834</td>\n",
       "      <td>-0.805056</td>\n",
       "      <td>-0.716543</td>\n",
       "      <td>-0.358055</td>\n",
       "      <td>-1.156855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.493587</td>\n",
       "      <td>-0.962834</td>\n",
       "      <td>-0.685709</td>\n",
       "      <td>-0.543603</td>\n",
       "      <td>-0.503985</td>\n",
       "      <td>-0.708685</td>\n",
       "      <td>-0.622235</td>\n",
       "      <td>-1.024614</td>\n",
       "      <td>-1.225219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.488596</td>\n",
       "      <td>-0.934746</td>\n",
       "      <td>0.029585</td>\n",
       "      <td>-0.574389</td>\n",
       "      <td>-0.717949</td>\n",
       "      <td>-0.667131</td>\n",
       "      <td>-0.682487</td>\n",
       "      <td>-0.278017</td>\n",
       "      <td>-1.151662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.488596</td>\n",
       "      <td>-0.944109</td>\n",
       "      <td>-0.288323</td>\n",
       "      <td>0.124039</td>\n",
       "      <td>0.337607</td>\n",
       "      <td>0.367307</td>\n",
       "      <td>0.349657</td>\n",
       "      <td>-0.629004</td>\n",
       "      <td>-1.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.483605</td>\n",
       "      <td>-0.372985</td>\n",
       "      <td>0.983311</td>\n",
       "      <td>-0.838597</td>\n",
       "      <td>-0.879611</td>\n",
       "      <td>-0.928835</td>\n",
       "      <td>-0.894679</td>\n",
       "      <td>-1.138646</td>\n",
       "      <td>-1.372333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.483605</td>\n",
       "      <td>-0.944109</td>\n",
       "      <td>0.426971</td>\n",
       "      <td>0.988804</td>\n",
       "      <td>1.514411</td>\n",
       "      <td>1.510494</td>\n",
       "      <td>1.457772</td>\n",
       "      <td>-0.891376</td>\n",
       "      <td>-1.286661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.478614</td>\n",
       "      <td>-0.372985</td>\n",
       "      <td>1.380697</td>\n",
       "      <td>-0.523845</td>\n",
       "      <td>-0.544401</td>\n",
       "      <td>-0.564571</td>\n",
       "      <td>-0.598658</td>\n",
       "      <td>-0.884746</td>\n",
       "      <td>-1.375794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0   2.623352 -0.672591           -1.083095     1.366966        1.771168   \n",
       "1   2.543496 -0.574283           -0.765186     2.303412        3.240388   \n",
       "2   2.498578 -0.906658           -0.924141    -0.880871       -0.865347   \n",
       "3   2.493587 -0.930065           -1.162572    -0.522007       -0.477834   \n",
       "4   2.493587 -0.962834           -0.685709    -0.543603       -0.503985   \n",
       "5   2.488596 -0.934746            0.029585    -0.574389       -0.717949   \n",
       "6   2.488596 -0.944109           -0.288323     0.124039        0.337607   \n",
       "7   2.483605 -0.372985            0.983311    -0.838597       -0.879611   \n",
       "8   2.483605 -0.944109            0.426971     0.988804        1.514411   \n",
       "9   2.478614 -0.372985            1.380697    -0.523845       -0.544401   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0   -0.362989   -0.072107      -1.251624           -1.213104  \n",
       "1   -0.262197   -0.095684      -1.079867           -1.098875  \n",
       "2   -0.965969   -1.002085      -1.168851           -1.050414  \n",
       "3   -0.805056   -0.716543      -0.358055           -1.156855  \n",
       "4   -0.708685   -0.622235      -1.024614           -1.225219  \n",
       "5   -0.667131   -0.682487      -0.278017           -1.151662  \n",
       "6    0.367307    0.349657      -0.629004           -1.078971  \n",
       "7   -0.928835   -0.894679      -1.138646           -1.372333  \n",
       "8    1.510494    1.457772      -0.891376           -1.286661  \n",
       "9   -0.564571   -0.598658      -0.884746           -1.375794  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.concat([housing_train_df, housing_test_df], ignore_index = True)\n",
    "housing_df = (housing_df - housing_df.mean()) / housing_df.std() \n",
    "\n",
    "housing_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dn3xgs9VNihx",
    "outputId": "6c155843-00c9-4be2-e5be-fc1e2bb09108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20000, Training: 16000, Testing: 4000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "housing_train_df, housing_test_df = train_test_split(housing_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total {len(housing_df)}, Training: {len(housing_train_df)}, Testing: {len(housing_test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y08VRcFGOVIj"
   },
   "source": [
    "## Construct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "u0IBXNCjOKVK"
   },
   "outputs": [],
   "source": [
    "class HousingDataset(Dataset): # inherit Dataset\n",
    "\n",
    "  def __init__(self, dataframe):\n",
    "    self.dataframe = dataframe\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    row = self.dataframe.iloc[index].to_numpy().astype('float32') # using index to locate a data row\n",
    "    features = row[0:-1] # get all columns except last one\n",
    "    label = row[-1] # last column => we want to predict\n",
    "    return features, label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KjVgB8VFObbd"
   },
   "outputs": [],
   "source": [
    "setup_seed(8888)\n",
    "\n",
    "train_dataset = HousingDataset(housing_train_df.astype('float32'))\n",
    "test_dataset = HousingDataset(housing_test_df.astype('float32'))\n",
    "\n",
    "train_batch_size = int(len(train_dataset))\n",
    "test_batch_size = int(len(test_dataset))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = train_batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = test_batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21uvrI4FOjPM",
    "outputId": "39b8812f-8dc2-467c-941b-5e67ed0780ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15l6wel2OyVu"
   },
   "source": [
    "## SLFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4o_ldOndOxzK"
   },
   "outputs": [],
   "source": [
    "class SLFN(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, D_in, H, D_out, activation_func, initial_weights = None):\n",
    "    super(SLFN, self).__init__()\n",
    "    self.fc1 = torch.nn.Linear(D_in, H)\n",
    "    self.fc2 = torch.nn.Linear(H, D_out)\n",
    "    self.bn1 = torch.nn.BatchNorm1d(H) # batch normalization => normalize between fc and activation func\n",
    "    self.dropout = torch.nn.Dropout(p=0.5) # inverted drop out\n",
    "    \n",
    "    self.activation_func = activation_func\n",
    "    if activation_func == 'ReLU':\n",
    "      self.relu = torch.nn.ReLU()\n",
    "    if activation_func == 'Tanh':\n",
    "      self.tanh = torch.nn.Tanh()\n",
    "\n",
    "    self.initial_weights = initial_weights\n",
    "    if self.initial_weights == 'small random number':\n",
    "      # H = W * X + B ; X = D_in => linear algebra\n",
    "      # D_in (1, D_in), W (D_in, H)\n",
    "      self.fc1.weight = torch.nn.Parameter(0.01 * torch.FloatTensor(np.random.randn(H, D_in)))\n",
    "      self.fc2.weight = torch.nn.Parameter(0.01 * torch.FloatTensor(np.random.randn(D_out, H)))\n",
    "    if self.initial_weights == 'Xavier':\n",
    "      torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "      torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    if self.initial_weights == 'Kaiming':\n",
    "      torch.nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "      torch.nn.init.kaiming_uniform_(self.fc2.weight)\n",
    "  \n",
    "  def forward(self, x): # input\n",
    "    fc1 = self.fc1(x) \n",
    "\n",
    "    # activation\n",
    "    activation = None\n",
    "    if self.activation_func == 'ReLU':\n",
    "      activation = self.relu(fc1)\n",
    "    if self.activation_func == 'Tanh':\n",
    "      activation = self.tanh(fc1)\n",
    "    \n",
    "    pred = self.fc2(activation) \n",
    "    return pred\n",
    "\n",
    "  # inverted drop out (don't affect at testing phase)\n",
    "  def forward_do(self, x):\n",
    "    fc1 = self.fc1(x)\n",
    "    do1 = self.dropout(fc1)\n",
    "\n",
    "    # activation\n",
    "    activation = None\n",
    "    if self.activation_func == 'ReLU':\n",
    "      activation = self.relu(fc1)\n",
    "    if self.activation_func == 'Tanh':\n",
    "      activation = self.tanh(fc1)\n",
    "\n",
    "    pred = self.fc2(activation) \n",
    "    return pred\n",
    "\n",
    "  # input -> FC1 -> BN1 -> ReLU -> FC2 -> output\n",
    "  def forward_bn(self, x): # input\n",
    "    fc1 = self.fc1(x) \n",
    "    bn1 = self.bn1(fc1) \n",
    "\n",
    "    # activation\n",
    "    activation = None\n",
    "    if self.activation_func == 'ReLU':\n",
    "      activation = self.relu(bn1)\n",
    "    if self.activation_func == 'Tanh':\n",
    "      activation = self.tanh(bn1)\n",
    "    \n",
    "    pred = self.fc2(activation) \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oNEYGky3iTUP"
   },
   "outputs": [],
   "source": [
    "D_in = len(housing_train_df.columns) - 1 \n",
    "D_out = 1 \n",
    "hidden_nodes = [5, 8, 11] \n",
    "learning_rate = 1e-4 \n",
    "loss_fn = torch.nn.MSELoss().to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJVN3xZ1O87l"
   },
   "source": [
    "## Weight Tuning EB and Regularizing EB\n",
    "We only show regularizing algorithm </br>\n",
    "<img\n",
    "width=\"600px\"\n",
    "src=\"https://lh3.googleusercontent.com/fife/APg5EOYOXcEzwpZUa-FLsXeR6yMrJ5rBcorGJm1VsaPjEF5gQYWzduPuyIx57aKhJ0-MY5feL2NlTm-DvXXEqApk9DQ9DBQVM7Ue6urUwcBG9499VknBAfKf18x0JY3mjT2B4pcFqY-zqeUDtj8f3inLFFSmqio1Gwk-IelGawU4YSZYB3DNsJ55OyEH5atm7Qn4_lFxh_79kXGa3SD-j9VQmiMWcJGnf0QxOKWq8D5dmecd5XIldK_xGbIQGug0hObWijKU6Q6C-vTIk8rM85qTx6NEzau-mOKAP0m0BwhcmiwWAUeDzdayUVTJZ6PzyITXbTTbGbJRcVTxzmiYYsaK6tvs1YMdfdJZoLVlRuXRpQLX0BxQrPL0pAxgP3J1ty-WSZXrd1aAcdKgs5TOdHWtkac-NBVTv4MQQYahX7O595IIdkNSawJ0JykDYC9KcY0tKXH9NkKPGq2TwlIn5KHuUYoCz0ztSAIziHF2HqWPqGxHhDnYDG8bgITMRP-P6-czrwPUaFB0FjSq-3KDmfkoCf7kWH7owyhE1aOckgmiw4zdY1n6qXZPEipj5WD_hSG2zoibeuvdVGZmbasAehh6J7RHKQn1U4Q09cBN15Z2Vkl6xulV2rR6poGV5NIft5YuOJIwNvRSuAaEFzwGN8vpapqTKdcCbrrAfD7u4VHD1Wnej00pbwNZQKzJRWVrP0BvySR2uOu696M3IvtTW8bPNMMqECpIMX72qqRGtofr_emyoPr_YQMt0dDuZ7jYpFzI3CFAWRpmXLdfAAHnfuuLtaOYhv6rD-2DoHJOCTelW2oXx614DHH2e03qD_fGhLpZ3aCAUGGFKhdUvRWoS0aWCx4p4UbW1SLTanmuxdqVue8QyQY9B6Bpxl1QeQe3ZvbuzFskY4IDPlP8AvI13QEN4d8CcMEhZH7155KmBPUGGpZGekw2xx0Ns5KNyB5mXIjVnIraYwhW1fX8rbLdvKcWw53Mpeo2BsS5STdIKEQjNEr1xT54o0giiQmKiRIklDnYOi8HPaRQ_WK-icof1dlTCFUKd9KBwnzQRp-be_N-X1F5y05oABPq0Egb2yF_OIPXhVbUWYKw4OC8fBYbrnG9TgXfMwL26Su5AvKH9l2L2_wwMD4NCtUbSlck1T9OWWhhow8XD-4LeOULKNp5mjEZy_2dJvD57dtoU2KIrrMM8KjD02Ujf2ZVHPc_9fdhmF_l-0tT0T6DsMr_dU6xNU95JIGgm-prmRbP28LHLPrhweASm8cljKgynbYqJvZueKDRq6Z7AwTiVlH3A3M-ZiMCzEIMit9mDcn1-ms9_HBNRa8p-h-ZGQMw9v7r7Zit1l3XIeHu_9rZb2BzLHNKLvFDgQVE4c_VuIJC7VsI1iLp5313UgOBrgSfEmgNBNsAX7TYJSOiPxMbvqY5F63AGWL790UNWeXWNKDINR6NI6WcApe-OTeM2T-d4J8BkRA3fcOulP-m4Yjmd6uqulUZKx3BVGjOfFlzyqsFdsA8bcTYb8RuM9SNs4jxHIlG4z-ssDE6mvMevmBJLbepIIxOW1HcPmWWg9VSe8nQs9zMbQUH6rqhgb-KklaUhS8_6XrbcGgLJXc=w1466-h1622\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5jWEw_7O0Su"
   },
   "source": [
    "### Weight Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y4tcJldXO1hP"
   },
   "outputs": [],
   "source": [
    "setup_seed(8888)\n",
    "epoch_bound = 100 # EB\n",
    "epsilon = 0.995 # LG\n",
    "\n",
    "model_EB_LG = SLFN(D_in, hidden_nodes[1], D_out, 'ReLU', 'small random number').to(device)\n",
    "optimizer_EB_LG = torch.optim.Adam(model_EB_LG.parameters(), lr = learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZ6APzB3jCgS",
    "outputId": "1ba4b79b-6bf5-4dbb-e9c9-72d4267718e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss: 0.9985405206680298\n",
      "----------------------\n",
      "10\n",
      "loss: 0.9981357455253601\n",
      "----------------------\n",
      "20\n",
      "loss: 0.997719407081604\n",
      "----------------------\n",
      "30\n",
      "loss: 0.9972875714302063\n",
      "----------------------\n",
      "40\n",
      "loss: 0.9968356490135193\n",
      "----------------------\n",
      "50\n",
      "loss: 0.9963579773902893\n",
      "----------------------\n",
      "60\n",
      "loss: 0.9958486557006836\n",
      "----------------------\n",
      "70\n",
      "loss: 0.9953014850616455\n",
      "----------------------\n",
      "77th epoch\n",
      "loss: 0.9949528574943542\n",
      "Accetable SLFN!\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "loss = np.inf\n",
    "\n",
    "while t < epoch_bound and loss > epsilon:\n",
    "  for batch, (X, y) in enumerate(train_dataloader): \n",
    "    # forward \n",
    "    pred = model_EB_LG(X.to(device))\n",
    "    y = y.unsqueeze(1)\n",
    "    loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "    optimizer_EB_LG.step()\n",
    "    optimizer_EB_LG.zero_grad()\n",
    "\n",
    "  if t % 10 == 0:\n",
    "    print(f\"{t}\")\n",
    "    print(f\"loss: {loss}\")\n",
    "    print(\"----------------------\")\n",
    "\n",
    "  t+=1\n",
    "\n",
    "print(f\"{t}th epoch\")\n",
    "print(f\"loss: {loss}\")\n",
    "if loss < epsilon:\n",
    "  print(\"Accetable SLFN!\")\n",
    "else:\n",
    "  print(\"Unaccetable SLFN!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPBc8ntpO2AI"
   },
   "source": [
    "### Regularizing - Epoch Bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nH2ijGuO5BT",
    "outputId": "e79dd1d7-43fa-4f21-95b7-d8a4941ed5ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Parameter containing:\n",
       " tensor([[-2.3301e-03,  1.2845e-03,  4.2715e-05,  2.3085e-02, -6.6211e-05,\n",
       "          -9.3066e-03, -7.8626e-03, -8.3803e-04],\n",
       "         [ 1.9890e-03, -6.8969e-03,  2.3232e-02,  1.7199e-02, -7.4539e-03,\n",
       "          -7.1757e-03,  2.0018e-02,  1.7251e-02],\n",
       "         [-2.1205e-02, -7.7699e-03, -1.8071e-02,  2.0566e-02,  2.6478e-02,\n",
       "           2.6864e-03,  1.0895e-02,  5.8204e-03],\n",
       "         [-1.9347e-02, -3.0237e-02,  1.4859e-02,  4.8648e-04,  1.3996e-03,\n",
       "          -7.6157e-03,  1.5457e-02,  4.7646e-03],\n",
       "         [-1.5950e-02, -2.5518e-03,  1.0218e-03, -4.5401e-03,  5.7380e-03,\n",
       "          -2.9036e-04,  9.2622e-03,  2.0322e-02],\n",
       "         [-1.5914e-02, -1.1129e-02, -3.4936e-02, -1.3797e-02,  4.1254e-03,\n",
       "          -4.8289e-03,  1.0431e-02,  1.2035e-02],\n",
       "         [-8.8780e-03,  8.2943e-03, -1.0354e-02, -9.1499e-03, -3.8567e-03,\n",
       "           1.4116e-02, -6.6725e-03,  4.8900e-05],\n",
       "         [ 1.6970e-02,  4.5419e-03,  1.3908e-02,  5.2627e-03,  3.7796e-04,\n",
       "          -7.4677e-04, -1.0265e-03,  1.0008e-02]], requires_grad=True): Parameter containing:\n",
       " tensor([[-2.3301e-03,  1.2845e-03,  4.2715e-05,  2.3085e-02, -6.6211e-05,\n",
       "          -9.3066e-03, -7.8626e-03, -8.3803e-04],\n",
       "         [ 1.9890e-03, -6.8969e-03,  2.3232e-02,  1.7199e-02, -7.4539e-03,\n",
       "          -7.1757e-03,  2.0018e-02,  1.7251e-02],\n",
       "         [-2.1205e-02, -7.7699e-03, -1.8071e-02,  2.0566e-02,  2.6478e-02,\n",
       "           2.6864e-03,  1.0895e-02,  5.8204e-03],\n",
       "         [-1.9347e-02, -3.0237e-02,  1.4859e-02,  4.8648e-04,  1.3996e-03,\n",
       "          -7.6157e-03,  1.5457e-02,  4.7646e-03],\n",
       "         [-1.5950e-02, -2.5518e-03,  1.0218e-03, -4.5401e-03,  5.7380e-03,\n",
       "          -2.9036e-04,  9.2622e-03,  2.0322e-02],\n",
       "         [-1.5914e-02, -1.1129e-02, -3.4936e-02, -1.3797e-02,  4.1254e-03,\n",
       "          -4.8289e-03,  1.0431e-02,  1.2035e-02],\n",
       "         [-8.8780e-03,  8.2943e-03, -1.0354e-02, -9.1499e-03, -3.8567e-03,\n",
       "           1.4116e-02, -6.6725e-03,  4.8900e-05],\n",
       "         [ 1.6970e-02,  4.5419e-03,  1.3908e-02,  5.2627e-03,  3.7796e-04,\n",
       "          -7.4677e-04, -1.0265e-03,  1.0008e-02]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1610,  0.3055, -0.0300,  0.1897,  0.1426, -0.3430, -0.2264,  0.1798],\n",
       "        requires_grad=True): Parameter containing:\n",
       " tensor([ 0.1610,  0.3055, -0.0300,  0.1897,  0.1426, -0.3430, -0.2264,  0.1798],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0031,  0.0089,  0.0118,  0.0120,  0.0236, -0.0116, -0.0129,  0.0139]],\n",
       "        requires_grad=True): Parameter containing:\n",
       " tensor([[ 0.0031,  0.0089,  0.0118,  0.0120,  0.0236, -0.0116, -0.0129,  0.0139]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0711], requires_grad=True): Parameter containing:\n",
       " tensor([-0.0711], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True): Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True): Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_seed(8888)\n",
    "\n",
    "# store weight first\n",
    "original_param = {}\n",
    "for param in model_EB_LG.parameters():\n",
    "  original_param[param] = param\n",
    "\n",
    "original_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IC3cpvLkoT5r"
   },
   "outputs": [],
   "source": [
    "# define loss function with regularization term (L2 regularizing)\n",
    "# using weight decay in pytorch\n",
    "# or simply add regularization term in training phase\n",
    "# tutorial: https://androidkt.com/how-to-add-l1-l2-regularization-in-pytorch-loss-function/\n",
    "optimizer_EB_r = torch.optim.Adam(model_EB_LG.parameters(), lr = learning_rate, weight_decay=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "at7Zz7mAnD1Z",
    "outputId": "6cd540a2-407d-4bc9-a5e4-7799f8f702dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss: 0.9948931932449341\n",
      "----------------------\n",
      "10\n",
      "loss: 0.9943547248840332\n",
      "----------------------\n",
      "20\n",
      "loss: 0.9937927722930908\n",
      "----------------------\n",
      "30\n",
      "loss: 0.9932039976119995\n",
      "----------------------\n",
      "40\n",
      "loss: 0.9925851821899414\n",
      "----------------------\n",
      "50\n",
      "loss: 0.9919338226318359\n",
      "----------------------\n",
      "60\n",
      "loss: 0.991248369216919\n",
      "----------------------\n",
      "70\n",
      "loss: 0.9905269145965576\n",
      "----------------------\n",
      "80\n",
      "loss: 0.9897679686546326\n",
      "----------------------\n",
      "90\n",
      "loss: 0.9889701008796692\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maoxunhuang/miniconda3/envs/jupyter/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16000])) that is different to the input size (torch.Size([16000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9944209456443787\n",
      "Acceptable SLFN!\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch_bound):\n",
    "  for batch, (X, y) in enumerate(train_dataloader):\n",
    "    pred = model_EB_LG(X.to(device))\n",
    "    y = y.unsqueeze(1)\n",
    "    loss = loss_fn(pred, y.to(device))\n",
    "    loss.backward()\n",
    "    optimizer_EB_r.step()\n",
    "    optimizer_EB_r.zero_grad()\n",
    "\n",
    "  if i%10 == 0:\n",
    "    print(f\"{i}\")\n",
    "    print(f\"loss: {loss}\")\n",
    "    print(\"----------------------\")\n",
    "\n",
    "# check if loss become smaller\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "  pred = model_EB_LG(X.to(device))\n",
    "  loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "  print(f\"loss: {loss}\")\n",
    "  if loss < epsilon:\n",
    "    print(\"Acceptable SLFN!\")\n",
    "  else:\n",
    "    # restore w\n",
    "    for param in model_EB_LG.parameters():\n",
    "        param = original_param[param]\n",
    "\n",
    "    print(\"Unacceptable SLFN!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vi4i-8zXDGXY",
    "outputId": "ad5674b7-67e8-4f93-ca75-b4a58cb93a9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.0693e-03, -4.3215e-03, -5.6311e-04,  9.1670e-03, -7.4932e-04,\n",
       "          -1.0473e-02, -3.0948e-03,  2.3294e-04],\n",
       "         [ 2.3225e-03, -3.1638e-03,  4.3707e-03, -3.2373e-03, -4.9237e-03,\n",
       "          -2.7476e-03,  4.5783e-03,  3.3791e-04],\n",
       "         [-3.5268e-02,  2.6270e-02, -3.4648e-02,  3.3563e-02,  3.9541e-02,\n",
       "           1.5955e-02,  2.3977e-02,  2.0737e-02],\n",
       "         [-7.4353e-03, -2.1060e-02, -1.8221e-04, -5.3089e-03, -1.5025e-04,\n",
       "          -3.2340e-03,  1.7427e-03, -4.9102e-03],\n",
       "         [-6.6476e-03,  3.6985e-03,  4.6561e-03, -2.0877e-02, -1.3792e-02,\n",
       "          -8.8523e-03, -1.0355e-02, -6.7030e-03],\n",
       "         [-7.2030e-03, -3.1051e-03, -2.5467e-02, -5.3232e-03, -3.0235e-05,\n",
       "           4.5297e-05,  2.5692e-03,  3.8326e-03],\n",
       "         [-1.4798e-03,  1.1196e-03, -2.5118e-03, -1.6580e-03,  1.2815e-05,\n",
       "           5.6011e-03, -3.2717e-04,  2.2905e-07],\n",
       "         [ 1.1136e-02, -3.2699e-03, -4.1204e-04, -6.0614e-03, -2.2509e-04,\n",
       "          -2.7102e-03, -6.3776e-04, -8.3897e-04]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1756,  0.3192, -0.0161,  0.2027,  0.1548, -0.3330, -0.2165,  0.1926],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0150,  0.0198,  0.0252,  0.0227,  0.0344, -0.0035, -0.0046,  0.0244]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0597], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[para for para in model_EB_LG.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7hZzW_ZPPwn"
   },
   "source": [
    "## Weight Tuning EB and Regularizing DO\n",
    "<img\n",
    "width=\"600px\"\n",
    "src=\"https://lh3.googleusercontent.com/fife/APg5EOYC0ll8hGHIiZfY_M_LwGljkHaznZiy3NsR3eRLTTBzLN2iTVLRbjYNC7qYTde627GD7FFL8pbEvIqt7SAfxPYLJcEmjQTlLCLE21cH1Bx9uX-pJs-qqr4RmHYj-b5hFAxOCf7FNXyxMzhLnMW1k9CH6ifMFhSe01Eh_pO3Wznx3ThwsTugJxCU9WwBhbL88QMl_U0tYayVLvrM7k5L8SbKT7nr7ZdwEmnJXqLBeNgyW21AjsCH10zVBLn09fsh0M5O-teFgbj2ubcARzwXErmYXGf0LXVpPZOdD_5O--ennLAvE72SNqeMBSpxSh-t9g9jVmANcxQrLZsOMyLWe3IAiI8ksDYmHYwY7VetKLivIq3vEdlHka4jXx0R0rW2AYVo__L5g086QU3SQQ9lXNMhbYJf8SaVIzImFoCslr03olYFKn5ZDSTW-Od-c4B3RHxrlIwBJ8or-XLwtPpWMRypuMQzYLEXtjXXNmKxDof7UsLvDjHVMaTAkqhU762Xqs4pIHtL55sC2kE6WA-SlKbBR_EU2_nmX8EgfJXGSbppeGud5KYXFZOrOvrDLo1mNZyObCxpauiI8Kp_zrmvbs6qHvKhm5ZuEIan0EX-pqggdGO6DOnsnqv0a4W9NICoJSQJmTBUipEmQ04gNvUsbNcHAsf4julAFwJF9nMC4nE4wHX0RX2geFgl-N3UgvGluTDpC0_MUEO9242g0BBp9YN42xO1gUcOI57AJeaLFRQlhs3IIe6OUGxMwhojnPR_0hhHrivsJnlHOKqQ3Dk4fJ5-MWN5r7YMatlu3f8Dcgb9FDu2pdiabiBPE089mo_nhqKGuI4szwGvA21uIVHXEqZoBW06Kz1BmDO32JzC07tldQmU3jHt43qK7qh-bXzlkcRMsbl3hxTxLZXu6ilBPSbaYJOXWKZy7jknNajypqAbvEmLkrtdsy3f6tS1KM5tcT4muvg5Yt_TyXroChEgwp805NCRXGK4ipQ5hT5sXF1sUh9xsACPfepTbRTQI8pqJ6boSMWW2nGihFd22TDNc7gts_WluF2je2H7iAtT4f7Sq6pL0FxS_n8WfVeY9EXy1Dm9G7X2Iz1JrOl40N7QOhHR-uDCk8gvEJ6YGWCa5r2OBxFEl6dbOnfrFKRwdpRO58JuDbto9bp0vmEs3WSK65EaVQMvVOuKquQ6KRTzpMaWH_HwsdHqxPUZP9p8DVIizcmCSeUUMboNuvN-sw_Ko0a5-EtHDKPzORaHkrSIjHHz8DPWifbX3y4xL98mtrwyAqJFmDwee0k-zK5NtXvif-sABZun7s9_mk4-T4jorB5TOvEZ_UrkcuhiVW7TeyoNgQtrRoG5wBMQe6jc8tczU7-9rVtawDgSs8GahrHLZVFzk8nzBSXRlkN8Jm_K1nCZPu3is7-CWWciIDWqYhhhVk04PwfA2qSfzYbCNZkfPULQUNBE531LxJTlRJLD560FIVntJr5lJAuZYhuVE_qkf1yUqQPaSrLN44k9LeulwSls01gISswztJqRa-g26Tcn-UroOY1794CPJw4Xiy4OEaFEu-tIGy9-guOLGmjHRlrSt9xeR5By37_4puruntPepxo=w1466-h1654\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v15xrIGLDIQl"
   },
   "source": [
    "### Regularizing - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "om5Q1SYIPTj8",
    "outputId": "53a58550-6002-45fd-b033-8597183caf8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss: 0.9941572546958923\n",
      "----------------------\n",
      "10\n",
      "loss: 0.9940251111984253\n",
      "----------------------\n",
      "20\n",
      "loss: 0.9939144849777222\n",
      "----------------------\n",
      "30\n",
      "loss: 0.9938153028488159\n",
      "----------------------\n",
      "40\n",
      "loss: 0.9937238693237305\n",
      "----------------------\n",
      "50\n",
      "loss: 0.9936386346817017\n",
      "----------------------\n",
      "60\n",
      "loss: 0.9935594201087952\n",
      "----------------------\n",
      "70\n",
      "loss: 0.9934861660003662\n",
      "----------------------\n",
      "80\n",
      "loss: 0.9934186935424805\n",
      "----------------------\n",
      "90\n",
      "loss: 0.9933569431304932\n",
      "----------------------\n",
      "loss: 0.9933006167411804\n",
      "Acceptable SLFN!\n"
     ]
    }
   ],
   "source": [
    "# use forward dropout mode\n",
    "for i in range(epoch_bound):\n",
    "  for batch, (X, y) in enumerate(train_dataloader):\n",
    "    pred = model_EB_LG.forward_do(X.to(device))\n",
    "    y = y.unsqueeze(1)\n",
    "    loss = loss_fn(pred, y.to(device))\n",
    "    loss.backward()\n",
    "    optimizer_EB_LG.step()\n",
    "    optimizer_EB_LG.zero_grad()\n",
    "\n",
    "  if i%10 == 0:\n",
    "    print(f\"{i}\")\n",
    "    print(f\"loss: {loss}\")\n",
    "    print(\"----------------------\")\n",
    "\n",
    "# check if loss become smaller\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "  pred = model_EB_LG(X.to(device)) # still use normal dropout => inverted dropout\n",
    "  loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "  print(f\"loss: {loss}\")\n",
    "  if loss < epsilon:\n",
    "    print(\"Acceptable SLFN!\")\n",
    "  else:\n",
    "    # restore w\n",
    "    for param in model_EB_LG.parameters():\n",
    "        param = original_param[param]\n",
    "\n",
    "    print(\"Unacceptable SLFN!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Clei5VVOO2Y_",
    "outputId": "2ee94efd-8db6-4146-d00d-c5a31e84bab1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-1.4626e-02, -1.1007e-02,  1.2337e-02,  3.5367e-02,  1.2116e-02,\n",
       "          -2.1780e-02,  4.3311e-03,  1.1459e-02],\n",
       "         [-9.2805e-03, -1.8172e-02,  3.4518e-02,  2.8436e-02,  3.6878e-03,\n",
       "          -1.8626e-02,  3.1213e-02,  2.8529e-02],\n",
       "         [-3.2836e-02, -1.9538e-02, -2.6162e-02,  3.1619e-02,  3.6669e-02,\n",
       "           9.9197e-03,  2.1304e-02,  1.7792e-02],\n",
       "         [-3.0410e-02, -4.1296e-02,  2.5918e-02,  1.1496e-02,  1.2327e-02,\n",
       "          -1.8847e-02,  2.6423e-02,  1.5820e-02],\n",
       "         [-2.6573e-02, -1.3171e-02,  1.1644e-02,  6.0349e-03,  1.6231e-02,\n",
       "          -1.1090e-02,  1.9787e-02,  3.0944e-02],\n",
       "         [-7.2030e-03, -3.1051e-03, -2.5467e-02, -5.3232e-03, -3.0235e-05,\n",
       "           4.5297e-05,  2.5692e-03,  3.8326e-03],\n",
       "         [-1.4798e-03,  1.1196e-03, -2.5118e-03, -1.6580e-03,  1.2815e-05,\n",
       "           5.6011e-03, -3.2717e-04,  2.2905e-07],\n",
       "         [ 6.0222e-03, -6.4136e-03,  2.4871e-02,  1.6177e-02,  1.1208e-02,\n",
       "          -1.1877e-02,  9.8351e-03,  2.0968e-02]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1731,  0.3163, -0.0181,  0.2001,  0.1526, -0.3330, -0.2165,  0.1901],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0143,  0.0192,  0.0233,  0.0227,  0.0342, -0.0035, -0.0046,  0.0246]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0618], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[para for para in model_EB_LG.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VM4uJXMvPERY"
   },
   "source": [
    "## Weight Tuning EB and Regularizing BN\n",
    "<img\n",
    "width=\"600px\"\n",
    "src=\"https://lh3.googleusercontent.com/fife/APg5EOZWqgUCaWuJEXYB_u2gNydfsuVESMdw8e7xDekXvUvJadbuatMTygf8vaCge_kQMijMXh4eQ8s_YXeoCZLWIQb3v7-uNr3CEeaVzgVgml4HVskAkGIedo5D6UawqAwj5h3JIYjvEXFrDT1PuLoXaLYYH3cdUsXUmCaIQEvGq4LUIsaieIxBeK7IUNbxUo0kHP4G0DIyw6r4FVS47eB4qZ6ld0vi-oztLmsgdCvLoTVWuEMczjDSqDkTYFVcXyAz1V36teZu_X_tldYGuPPiak_TLAhSxdPPRUmn6Q4uk3RHy8LLpsVdxQprGLscrfhyooRzpaPrvbww3aWvlAvvJIKgpJrA-i2VEqZ80_uzy63K2QCXtCrf8nB1qzpoZ0BkaNFsR861jQPIBVPBc_3VHu6x5uS1krCGYGJ0gOYVUanYifwMNf3_0axjXLMTGKlXT3dv--f43iKS42u_CCdOPS-m-L-1uWQZ9MnIGfaFy_royFQJfRN9IBg1sLAqqVWEaljUN-0v5gmCSIK_JZofJ_uKZqzlYeXt39mnS5j1uyTDstR4dCtUK_9_nj2K1gs0BvNDI84lIkp-jTwfJY1GFYsLkGqk-IT8QwxyIH3nUZRf1tjjMf2Otlhjqk6tnQo0WGEsljXFqcaIb_2GCjeFypoIYaiHaBM9-FjXu9JfU084LMJ88ZsKLrZs7f67_xYdi07jJkvBm4AbWPpu93bE0krhebc5MHo3xDOYwzM5D_E4Z8IbISLo-aOwOLkgAkEFhMg7IFW7XDlzBT61jxZXCIMnElT7derFfOcQl5eFmF8JSPtXAlys_pVDJJSedoZkCOZDQZwERR_kLOd6-IOFhUMSJUxX3TxmTuy3iFiqxR1ih3dblXtyAqFZ_leH3Nd5kyuW15W36PONtfHlH_y3zS4T2JaSAaGrkHhayvPccmxATRuR7yuM0Z9_milcDzrEyyjUv3ZtYHn2EZvE7p0DPClLWXx3IPzSnn0L9Aa5breswa1R3ouQas3Eg6jzbrourM8dU5uo8AVtVaQ5BdZT9LrFupzEe0j6m6bdbmjKOkj6WZBMEG2dk36Bp7VZJFArK96gkwt21VzxfkzztdC0pQir5lvFb3sSqdM4ktIfM9SFq7XksVKQIccWObhF-oyBJ-AGFMh4kRojcXtT6vcyIPwyKBhp2IXtbnFay1SOtydxoTFGcrbw5TUbkgj9TyT575XshKQONM_BD0N-T3H2sTVsR3dTIWgDzVWz1fvyEPSkuGUrfBuq6jfPEas5qRt6dDka75mOck6uN1NzaVnLZtb4rJWbbsn78S8bnmvID0DJqqgay7t2-IJhhFtbDUW_0uixjxgnYMrWIUPUEeZy8o89T5Ah5In_wMzn4qQCF0u0XJuuDx78JhzU0Qm5Tibb7Z7izv5HPCeRJDFmOpyVRogBR63j6yNDNMx9r2hm4gSSqwUB9SiZst5HSR1dJmvd60v1EZTS6b5GX9DpOBrcrQUSVTNS_cCNBqkTM0yCZZgIWgeLBrLgfH3np3JHjAtwRtsbG0w_UorOSeJkfLeMOCyg3u2McjXu5rGtIH5tNZzYsXofc_XzKRPCFXZKIFr6E6o=w1466-h1654\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sdlpMPnE7ZP"
   },
   "source": [
    "### Regularizing - Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtCmLCkLE_uH",
    "outputId": "1938ffa9-e0c2-4103-ee96-812dd5a925a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss: 0.9195564985275269\n",
      "----------------------\n",
      "10\n",
      "loss: 0.901084303855896\n",
      "----------------------\n",
      "20\n",
      "loss: 0.8788357377052307\n",
      "----------------------\n",
      "30\n",
      "loss: 0.8598382472991943\n",
      "----------------------\n",
      "40\n",
      "loss: 0.8441941142082214\n",
      "----------------------\n",
      "50\n",
      "loss: 0.8298944234848022\n",
      "----------------------\n",
      "60\n",
      "loss: 0.8161411881446838\n",
      "----------------------\n",
      "70\n",
      "loss: 0.8026629686355591\n",
      "----------------------\n",
      "80\n",
      "loss: 0.789283812046051\n",
      "----------------------\n",
      "90\n",
      "loss: 0.7760411500930786\n",
      "----------------------\n",
      "loss: 0.9933959245681763\n",
      "Acceptable SLFN!\n"
     ]
    }
   ],
   "source": [
    "# use original model\n",
    "# use forward dropout mode\n",
    "for i in range(epoch_bound):\n",
    "  for batch, (X, y) in enumerate(train_dataloader):\n",
    "    pred = model_EB_LG.forward_bn(X.to(device))\n",
    "    y = y.unsqueeze(1)\n",
    "    loss = loss_fn(pred, y.to(device))\n",
    "    loss.backward()\n",
    "    optimizer_EB_LG.step()\n",
    "    optimizer_EB_LG.zero_grad()\n",
    "\n",
    "  if i%10 == 0:\n",
    "    print(f\"{i}\")\n",
    "    print(f\"loss: {loss}\")\n",
    "    print(\"----------------------\")\n",
    "\n",
    "# check if loss become smaller\n",
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "  pred = model_EB_LG(X.to(device)) # still use normal dropout => inverted dropout\n",
    "  loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "  print(f\"loss: {loss}\")\n",
    "  if loss < epsilon:\n",
    "    print(\"Acceptable SLFN!\")\n",
    "  else:\n",
    "    # restore w\n",
    "    for param in model_EB_LG.parameters():\n",
    "        param = original_param[param]\n",
    "\n",
    "    print(\"Unacceptable SLFN!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkr-tw5bO34l",
    "outputId": "c769c448-2353-45c0-e271-408eb73163bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0026, -0.0077, -0.0185,  0.0004,  0.0021, -0.0063,  0.0034,  0.0148],\n",
       "         [ 0.0057, -0.0095,  0.0117, -0.0275, -0.0146, -0.0146, -0.0002,  0.0046],\n",
       "         [-0.0591,  0.0491, -0.0539,  0.0408,  0.0451,  0.0227,  0.0299,  0.0311],\n",
       "         [-0.0108, -0.0419,  0.0089, -0.0135,  0.0053,  0.0038,  0.0109,  0.0002],\n",
       "         [-0.0365,  0.0330,  0.0157, -0.0288, -0.0209, -0.0151, -0.0170, -0.0242],\n",
       "         [ 0.0017, -0.0121, -0.0150,  0.0016,  0.0111,  0.0037,  0.0134,  0.0168],\n",
       "         [ 0.0055, -0.0057, -0.0054,  0.0017,  0.0062,  0.0039,  0.0052,  0.0062],\n",
       "         [ 0.0305, -0.0199, -0.0149, -0.0137,  0.0062,  0.0041,  0.0085,  0.0028]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1916,  0.3328,  0.0007,  0.2149,  0.1637, -0.3329, -0.2165,  0.2041],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0170,  0.0226,  0.0310,  0.0252,  0.0381, -0.0138, -0.0148,  0.0265]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0541], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9967, 0.9955, 0.9956, 0.9968, 0.9902, 1.0044, 1.0043, 0.9968],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0020, -0.0037,  0.0097, -0.0021, -0.0035, -0.0039, -0.0050, -0.0018],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[para for para in model_EB_LG.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_EB_LG, 'model_EB_LG.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKrpzwhwgJuqN5NcwHorxN",
   "collapsed_sections": [
    "15l6wel2OyVu",
    "VM4uJXMvPERY"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
